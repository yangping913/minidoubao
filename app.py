from flask import Flask, request, jsonify, Response, render_template
import time
import threading
import json
import os
import requests
from datetime import datetime

app = Flask(__name__)
app.secret_key = os.getenv('FLASK_SECRET_KEY', 'minidoubao-secret-key')

# ===== é…ç½®ä¿¡æ¯ =====
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '').strip()
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
OLLAMA_API_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL_NAME = os.getenv('OLLAMA_MODEL_NAME', 'qwen:0.5b').strip()  # å…³é”®æ–°å¢è¡Œ


# ===== è·¨åŸŸæ”¯æŒ =====
@app.after_request
def add_cors_headers(response):
    """æ·»åŠ CORSå¤´ä¿¡æ¯"""
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
    return response


# ===== æ ¸å¿ƒä¸šåŠ¡æ¨¡å— =====
class ModelManager:
    """æ¨¡å‹çŠ¶æ€ä¸åå¥½ç®¡ç†å™¨"""

    def __init__(self):
        self.model_status = {'deepseek': False, 'ollama': False}
        self.preference = 'auto'
        self.request_count = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
        self.is_processing = False

    def update_status(self):
        """æ›´æ–°æ¨¡å‹çŠ¶æ€"""
        with self.lock:
            # æ£€æŸ¥DeepSeekçŠ¶æ€
            try:
                if DEEPSEEK_API_KEY:
                    headers = {'Authorization': f'Bearer {DEEPSEEK_API_KEY}'}
                    response = requests.get(
                        "https://api.deepseek.com/v1/models",
                        headers=headers,
                        timeout=5
                    )
                    self.model_status['deepseek'] = response.status_code == 200
                else:
                    self.model_status['deepseek'] = False
            except:
                self.model_status['deepseek'] = False

            # æ£€æŸ¥OllamaçŠ¶æ€
            try:
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                self.model_status['ollama'] = response.status_code == 200
            except:
                self.model_status['ollama'] = False

            return self.model_status

    def get_status(self):
        """è·å–å®Œæ•´çŠ¶æ€ä¿¡æ¯"""
        return {
            "deepseek": self.model_status['deepseek'],
            "ollama": self.model_status['ollama'],
            "preference": self.preference,
            "request_count": self.request_count,
            "uptime": int(time.time() - self.start_time)
        }

    def set_preference(self, model):
        """è®¾ç½®æ¨¡å‹åå¥½"""
        if model in ['auto', 'deepseek', 'ollama']:
            self.preference = model
            return True
        return False

    def select_model(self):
        """æ™ºèƒ½é€‰æ‹©å½“å‰æ´»è·ƒæ¨¡å‹"""
        if self.preference == 'deepseek' and self.model_status['deepseek']:
            return 'deepseek'
        elif self.preference == 'ollama' and self.model_status['ollama']:
            return 'ollama'
        elif self.preference == 'auto':
            if self.model_status['deepseek']:
                return 'deepseek'
            elif self.model_status['ollama']:
                return 'ollama'
        return None

    def increment_count(self):
        """å¢åŠ è¯·æ±‚è®¡æ•°"""
        with self.lock:
            self.request_count += 1


class NaturalContextManager:
    """è‡ªç„¶è¯­è¨€ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - å®Œå…¨æ— ç¡¬ç¼–ç """

    def __init__(self):
        self.conversation_history = []
        self.max_history = 10

    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # ä¿æŒå†å²è®°å½•é•¿åº¦
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]

    def build_context_prompt(self, current_message):
        """æ„å»ºä¸Šä¸‹æ–‡æç¤ºè¯ - å®Œå…¨æ— ç¡¬ç¼–ç """
        # åŸºç¡€ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®å®Œæ•´çš„å¯¹è¯å†å²æä¾›å‡†ç¡®ã€è¿è´¯çš„å›ç­”ã€‚

å¯¹è¯æŒ‡å—ï¼š
1. ä»”ç»†é˜…è¯»å’Œç†è§£æ•´ä¸ªå¯¹è¯å†å²
2. å¦‚æœç”¨æˆ·æåˆ°è¿‡ä¸ªäººä¿¡æ¯ï¼ˆå¦‚åå­—ã€åœ°ç‚¹ã€åå¥½ç­‰ï¼‰ï¼Œè¯·è‡ªç„¶åœ°ä½¿ç”¨è¿™äº›ä¿¡æ¯
3. ä¿æŒå›ç­”ä¸ä¹‹å‰å¯¹è¯çš„ä¸€è‡´æ€§
4. å¦‚æœç”¨æˆ·çš„é—®é¢˜éœ€è¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·å‚è€ƒå†å²å¯¹è¯

å½“å‰å¯¹è¯å†å²ï¼š"""

        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæ— å…³é”®è¯è¿‡æ»¤ï¼‰
        for i, msg in enumerate(self.conversation_history[-5:]):  # æœ€è¿‘5æ¡æ¶ˆæ¯
            system_prompt += f"\n{msg['role']}: {msg['content']}"

        system_prompt += f"\n\nå½“å‰ç”¨æˆ·æ¶ˆæ¯: {current_message}"
        system_prompt += "\n\nè¯·åŸºäºä»¥ä¸Šå®Œæ•´å¯¹è¯å†å²æä¾›æœ‰å¸®åŠ©çš„å›ç­”ã€‚"

        return system_prompt

    def get_recent_messages(self, count=3):
        """è·å–æœ€è¿‘çš„å¯¹è¯æ¶ˆæ¯"""
        return self.conversation_history[-count:] if self.conversation_history else []


# ===== å…¨å±€åˆå§‹åŒ– =====
model_manager = ModelManager()
context_manager = NaturalContextManager()


# ===== è·¯ç”±å®ç° =====
@app.route('/')
def index():
    """æ ¹è·¯ç”± - è¿”å›å‰ç«¯é¡µé¢"""
    return render_template('index.html')


@app.route('/api/models/status', methods=['GET'])
def get_model_status():
    """è·å–æ¨¡å‹çŠ¶æ€"""
    model_manager.update_status()
    return jsonify(model_manager.get_status())


@app.route('/api/models/switch', methods=['POST'])
def switch_model():
    """åˆ‡æ¢æ¨¡å‹åå¥½"""
    data = request.get_json()
    if not data or 'model' not in data:
        return jsonify({"error": "ç¼ºå°‘æ¨¡å‹å‚æ•°"}), 400

    model = data['model']
    if model_manager.set_preference(model):
        return jsonify({
            "status": "success",
            "preference": model,
            "message": f"å·²åˆ‡æ¢åˆ°{model}æ¨¡å¼"
        })
    return jsonify({"error": "æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©"}), 400


@app.route('/api/stream-chat', methods=['POST'])
def stream_chat():
    """å¤„ç†æµå¼èŠå¤©è¯·æ±‚ - æ— ç¡¬ç¼–ç ç‰ˆæœ¬"""
    data = request.get_json()
    if not data or 'message' not in data:
        return jsonify({"error": "ç¼ºå°‘æ¶ˆæ¯å†…å®¹"}), 400

    message = data['message'].strip()
    if not message:
        return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400

    if model_manager.is_processing:
        return jsonify({"error": "ç³»ç»Ÿå¿™ï¼Œè¯·ç¨åé‡è¯•"}), 429

    model_manager.is_processing = True
    model_manager.increment_count()

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
    context_manager.add_message("user", message)

    def generate():
        """ç”Ÿæˆæµå¼å“åº”"""
        try:
            # é€‰æ‹©æ¨¡å‹
            selected_model = model_manager.select_model()
            if not selected_model:
                yield f"data: {json.dumps({'error': 'æ— å¯ç”¨æ¨¡å‹'})}\n\n"
                return

            # æ„å»ºè‡ªç„¶è¯­è¨€ä¸Šä¸‹æ–‡æç¤º
            context_prompt = context_manager.build_context_prompt(message)

            # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è°ƒç”¨API
            if selected_model == 'deepseek' and DEEPSEEK_API_KEY:
                # DeepSeek APIè°ƒç”¨ - ä¿æŒä¸å˜
                headers = {
                    'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
                    'Content-Type': 'application/json'
                }

                # ä½¿ç”¨è‡ªç„¶è¯­è¨€ä¸Šä¸‹æ–‡æç¤º
                messages = [{"role": "system", "content": context_prompt}]

                data = {
                    "model": "deepseek-chat",
                    "messages": messages,
                    "stream": True,
                    "temperature": 0.7,
                    "max_tokens": 2000
                }

                response = requests.post(
                    DEEPSEEK_API_URL,
                    json=data,
                    headers=headers,
                    stream=True,
                    timeout=30
                )

                if response.status_code != 200:
                    yield f"data: {json.dumps({'error': f'APIé”™è¯¯: {response.status_code}'})}\n\n"
                    return

                # å¤„ç†DeepSeekæµå¼å“åº” - ä¿æŒä¸å˜
                full_response = ""
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data:'):
                            data_str = line_str[5:].strip()
                            if data_str == '[DONE]':
                                break
                            try:
                                chunk = json.loads(data_str)
                                if 'choices' in chunk and chunk['choices']:
                                    delta = chunk['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        full_response += content
                                        yield f"data: {json.dumps({'content': content})}\n\n"
                            except json.JSONDecodeError:
                                continue

                # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
                if full_response.strip():
                    context_manager.add_message("assistant", full_response)

                yield "data: [DONE]\n\n"

            else:
                # Ollamaæ¨¡å‹å¤„ç† - å®ç°çœŸæ­£çš„æµå¼å“åº”
                context_prompt = context_manager.build_context_prompt(message)

                # æ„å»ºOllama APIè¯·æ±‚
                # ä¿®æ”¹åä»£ç ï¼ˆè¯»å–é…ç½®ï¼Œæ— ç¡¬ç¼–ç ï¼‰
                ollama_data = {
                    "model": OLLAMA_MODEL_NAME,  # æ›¿æ¢ä¸ºé…ç½®å˜é‡ï¼Œåç»­æ¢æ¨¡å‹æ”¹ç¯å¢ƒå˜é‡å³å¯
                    "prompt": context_prompt + "\n\nç”¨æˆ·æ¶ˆæ¯: " + message,
                    "stream": True
                }

                try:
                    # è°ƒç”¨Ollama API
                    response = requests.post(
                        OLLAMA_API_URL,
                        json=ollama_data,
                        stream=True,
                        timeout=30
                    )

                    if response.status_code != 200:
                        yield f"data: {json.dumps({'error': f'Ollama APIé”™è¯¯: {response.status_code}'})}\n\n"
                        return

                    # å¤„ç†Ollamaæµå¼å“åº”
                    full_response = ""
                    for line in response.iter_lines():
                        if line:
                            try:
                                chunk = json.loads(line)
                                if 'response' in chunk:
                                    content = chunk['response']
                                    if content:
                                        full_response += content
                                        yield f"data: {json.dumps({'content': content})}\n\n"
                                if chunk.get('done', False):
                                    break
                            except json.JSONDecodeError:
                                continue

                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
                    if full_response.strip():
                        context_manager.add_message("assistant", full_response)

                    yield "data: [DONE]\n\n"

                except Exception as e:
                    yield f"data: {json.dumps({'error': f'Ollamaè¯·æ±‚å¤±è´¥: {str(e)}'})}\n\n"

        except Exception as e:
            error_msg = f"è¯·æ±‚å¤±è´¥: {str(e)}"
            yield f"data: {json.dumps({'error': error_msg})}\n\n"
        finally:
            model_manager.is_processing = False

    return Response(generate(), mimetype='text/event-stream')

@app.route('/api/debug/context', methods=['GET'])
def debug_context():
    """è°ƒè¯•ç«¯ç‚¹ï¼šæŸ¥çœ‹å½“å‰å¯¹è¯å†å²"""
    return jsonify({
        "conversation_count": len(context_manager.conversation_history),
        "recent_messages": context_manager.get_recent_messages(5)
    })


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "deepseek_configured": bool(DEEPSEEK_API_KEY),
        "conversation_count": len(context_manager.conversation_history)
    })


# ===== åå°ä»»åŠ¡ =====
def background_status_updater():
    """åå°çŠ¶æ€æ›´æ–°çº¿ç¨‹"""
    while True:
        time.sleep(30)
        model_manager.update_status()


# ===== é”™è¯¯å¤„ç† =====
@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "ç«¯ç‚¹ä¸å­˜åœ¨"}), 404


@app.errorhandler(500)
def server_error(error):
    return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


# ===== å¯åŠ¨åº”ç”¨ =====
if __name__ == '__main__':
    # å¯åŠ¨åå°çº¿ç¨‹
    threading.Thread(target=background_status_updater, daemon=True).start()

    # é…ç½®éªŒè¯
    if not DEEPSEEK_API_KEY:
        print("âš ï¸  è­¦å‘Š: DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    elif len(DEEPSEEK_API_KEY) != 51:
        print("âš ï¸  è­¦å‘Š: DeepSeek APIå¯†é’¥æ ¼å¼å¼‚å¸¸")
    else:
        print("âœ… APIå¯†é’¥é…ç½®æ­£å¸¸")

    print("ğŸš€ è¿·ä½ è±†åŒ…åç«¯æœåŠ¡å¯åŠ¨æˆåŠŸ")
    print("ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:5000")
    print("ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†: è‡ªç„¶è¯­è¨€æ¨¡å¼ï¼ˆæ— ç¡¬ç¼–ç ï¼‰")
    print("ğŸ”§ å¯ç”¨APIç«¯ç‚¹:")
    print("   GET  /              - å‰ç«¯ç•Œé¢")
    print("   GET  /api/models/status    - è·å–æ¨¡å‹çŠ¶æ€")
    print("   GET  /health        - å¥åº·æ£€æŸ¥")
    print("   GET  /api/debug/context - è°ƒè¯•å¯¹è¯å†å²")
    print("   POST /api/models/switch   - åˆ‡æ¢æ¨¡å‹åå¥½")
    print("   POST /api/stream-chat     - æµå¼èŠå¤©æ¥å£")

    app.run(host='0.0.0.0', port=5000, debug=False)