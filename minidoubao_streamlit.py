# # minidoubao_streamlit.py
# import streamlit as st
# import requests
# import json
# import time
# import os
#
# # ç›´æ¥ä»ç¯å¢ƒå˜é‡è·å–åç«¯åœ°å€
# FLASK_BACKEND_URL = os.getenv("FLASK_BACKEND_URL", "http://localhost:5000")
#
# # é¡µé¢è®¾ç½®
# st.set_page_config(
#     page_title="è¿·ä½ è±†åŒ… AI åŠ©æ‰‹",
#     page_icon="ğŸ¤–",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )
#
# # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
# if "messages" not in st.session_state:
#     st.session_state.messages = []
#
# if "model_status" not in st.session_state:
#     st.session_state.model_status = {
#         "deepseek": False,
#         "ollama": False,
#         "preference": "auto",
#         "request_count": 0,
#         "uptime": 0
#     }
#
# if "processing" not in st.session_state:
#     st.session_state.processing = False
#
# if "last_model_check" not in st.session_state:
#     st.session_state.last_model_check = 0
#
#
# # å·¥å…·å‡½æ•°
# def get_model_status(force=False):
#     """è·å–æ¨¡å‹çŠ¶æ€ï¼Œå¸¦ç¼“å­˜æœºåˆ¶"""
#     current_time = time.time()
#     # 5ç§’ç¼“å­˜ï¼Œé¿å…é¢‘ç¹è¯·æ±‚
#     if not force and current_time - st.session_state.last_model_check < 5:
#         return True
#
#     try:
#         response = requests.get(f"{FLASK_BACKEND_URL}/api/models/status", timeout=5)
#         if response.status_code == 200:
#             new_status = response.json()
#             st.session_state.model_status = new_status
#             st.session_state.last_model_check = current_time
#             return True
#     except Exception as e:
#         st.error(f"è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥: {str(e)}")
#     return False
#
#
# def switch_model_preference(model):
#     """åˆ‡æ¢æ¨¡å‹åå¥½"""
#     try:
#         response = requests.post(
#             f"{FLASK_BACKEND_URL}/api/models/switch",
#             json={"model": model},
#             timeout=5
#         )
#         if response.status_code == 200:
#             result = response.json()
#             # å¼ºåˆ¶åˆ·æ–°æ¨¡å‹çŠ¶æ€
#             get_model_status(force=True)
#             st.success(f"å·²åˆ‡æ¢åˆ° {model} æ¨¡å¼")
#             return True
#         else:
#             st.error(f"åˆ‡æ¢å¤±è´¥: {response.json().get('error', 'æœªçŸ¥é”™è¯¯')}")
#     except Exception as e:
#         st.error(f"åˆ‡æ¢æ¨¡å‹å¤±è´¥: {str(e)}")
#     return False
#
#
# def clear_conversation():
#     """æ¸…ç©ºå¯¹è¯å†å²"""
#     try:
#         response = requests.post(f"{FLASK_BACKEND_URL}/api/context/clear", timeout=5)
#         if response.status_code == 200:
#             st.session_state.messages = []
#             st.success("å¯¹è¯å†å²å·²æ¸…ç©º")
#             return True
#     except Exception as e:
#         st.error(f"æ¸…ç©ºå¯¹è¯å¤±è´¥: {str(e)}")
#     return False
#
#
# def send_message(message):
#     """å‘é€æ¶ˆæ¯åˆ°åç«¯å¹¶å¤„ç†æµå¼å“åº”"""
#     st.session_state.processing = True
#
#     try:
#         # å‡†å¤‡è¯·æ±‚
#         response = requests.post(
#             f"{FLASK_BACKEND_URL}/api/stream-chat",
#             json={"message": message},
#             stream=True,
#             timeout=30
#         )
#
#         # æ£€æŸ¥å“åº”çŠ¶æ€
#         if response.status_code != 200:
#             st.error(f"è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
#             st.session_state.processing = False
#             return
#
#         # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ç•Œé¢
#         st.session_state.messages.append({"role": "user", "content": message})
#
#         # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼æ˜¾ç¤º
#         assistant_placeholder = st.empty()
#         full_response = ""
#
#         # å¤„ç†æµå¼å“åº”
#         for line in response.iter_lines():
#             if line:
#                 line_str = line.decode('utf-8')
#                 if line_str.startswith('data:'):
#                     data_str = line_str[5:].strip()
#                     if data_str == '[DONE]':
#                         break
#
#                     try:
#                         data = json.loads(data_str)
#                         if 'content' in data:
#                             full_response += data['content']
#                             assistant_placeholder.markdown(full_response + "â–Œ")
#                         elif 'error' in data:
#                             st.error(f"APIé”™è¯¯: {data['error']}")
#                             break
#                     except json.JSONDecodeError:
#                         continue
#
#         # æ›´æ–°æœ€ç»ˆå“åº”
#         if full_response:
#             assistant_placeholder.markdown(full_response)
#             st.session_state.messages.append({"role": "assistant", "content": full_response})
#
#         # åˆ·æ–°æ¨¡å‹çŠ¶æ€
#         get_model_status(force=True)
#
#     except Exception as e:
#         st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
#     finally:
#         st.session_state.processing = False
#
#
# # ä¾§è¾¹æ  - æ¨¡å‹çŠ¶æ€å’Œæ§åˆ¶
# with st.sidebar:
#     st.title("æ§åˆ¶é¢æ¿")
#     st.divider()
#
#     # æ¨¡å‹çŠ¶æ€
#     st.subheader("æ¨¡å‹çŠ¶æ€")
#     if st.button("åˆ·æ–°çŠ¶æ€", use_container_width=True):
#         get_model_status(force=True)
#
#     col1, col2 = st.columns(2)
#     with col1:
#         deepseek_status = "ğŸŸ¢ åœ¨çº¿" if st.session_state.model_status.get("deepseek") else "ğŸ”´ ç¦»çº¿"
#         st.metric("DeepSeek", deepseek_status)
#     with col2:
#         ollama_status = "ğŸŸ¢ åœ¨çº¿" if st.session_state.model_status.get("ollama") else "ğŸ”´ ç¦»çº¿"
#         st.metric("Ollama", ollama_status)
#
#     st.metric("è¯·æ±‚æ¬¡æ•°", st.session_state.model_status.get("request_count", 0))
#     uptime = st.session_state.model_status.get('uptime', 0)
#     st.metric("è¿è¡Œæ—¶é—´", f"{uptime}ç§’")
#
#     # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹
#     current_model = st.session_state.model_status.get("preference", "auto")
#     st.info(f"å½“å‰æ¨¡å¼: {current_model}")
#
#     # æ¨¡å‹é€‰æ‹©
#     st.divider()
#     st.subheader("æ¨¡å‹é€‰æ‹©")
#
#     # ä½¿ç”¨å•é€‰æŒ‰é’®é€‰æ‹©æ¨¡å‹
#     model_options = ["auto", "deepseek", "ollama"]
#     selected_model = st.radio(
#         "é€‰æ‹©æ¨¡å‹",
#         options=model_options,
#         index=model_options.index(current_model) if current_model in model_options else 0,
#         help="auto: è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ¨¡å‹\ndeepseek: ä¼˜å…ˆä½¿ç”¨DeepSeek\nollama: ä¼˜å…ˆä½¿ç”¨Ollama"
#     )
#
#     # åªæœ‰å½“é€‰æ‹©çš„æ¨¡å‹ä¸å½“å‰æ¨¡å‹ä¸åŒæ—¶æ‰æ˜¾ç¤ºåˆ‡æ¢æŒ‰é’®
#     if selected_model != current_model:
#         if st.button("åº”ç”¨é€‰æ‹©", use_container_width=True):
#             if switch_model_preference(selected_model):
#                 # æˆåŠŸåˆ‡æ¢åï¼Œé‡æ–°è¿è¡Œä»¥æ›´æ–°ç•Œé¢
#                 st.rerun()
#
#     # å…¶ä»–æ§åˆ¶
#     st.divider()
#     st.subheader("å…¶ä»–é€‰é¡¹")
#     if st.button("æ¸…ç©ºå¯¹è¯", use_container_width=True, type="secondary"):
#         clear_conversation()
#
#     if st.button("è°ƒè¯•ä¿¡æ¯", use_container_width=True, type="secondary"):
#         try:
#             response = requests.get(f"{FLASK_BACKEND_URL}/api/debug/context", timeout=5)
#             if response.status_code == 200:
#                 debug_info = response.json()
#                 st.write("è°ƒè¯•ä¿¡æ¯:", debug_info)
#         except Exception as e:
#             st.error(f"è·å–è°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}")
#
# # ä¸»ç•Œé¢ - èŠå¤©åŒºåŸŸ
# st.title("è¿·ä½ è±†åŒ… AI åŠ©æ‰‹")
# st.caption("åŸºäº Flask + Streamlit çš„æ™ºèƒ½èŠå¤©åŠ©æ‰‹")
#
# # æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])
#
# # ç”¨æˆ·è¾“å…¥
# if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", disabled=st.session_state.processing):
#     send_message(prompt)
#
# # åº•éƒ¨çŠ¶æ€æ 
# st.divider()
# status_text = "å°±ç»ª"
# if st.session_state.processing:
#     status_text = "æ­£åœ¨å¤„ç†è¯·æ±‚..."
#
# col1, col2, col3 = st.columns([1, 1, 2])
# with col1:
#     st.caption(f"çŠ¶æ€: {status_text}")
# with col2:
#     st.caption(f"æ¨¡å¼: {st.session_state.model_status.get('preference', 'auto')}")
# with col3:
#     st.caption(f"åç«¯: {FLASK_BACKEND_URL}")
#
# # åˆå§‹åŠ è½½æ—¶è·å–æ¨¡å‹çŠ¶æ€
# if not st.session_state.model_status.get("request_count", 0) > 0:
#     get_model_status(force=True)